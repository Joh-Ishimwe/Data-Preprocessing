{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joh-Ishimwe/Data-Preprocessing/blob/master/Formative_2_Data_Preprocessing_Assignment_for_Machine_Learning_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formative 2: Data Preprocessing Assignment for Machine Learning Pipeline\n",
        "**Team Members**:  \n",
        "\n",
        "*   Liliane Kayitesi\n",
        "*   Ines Ikirezi\n",
        "*   Josiane Ishimwe\n",
        "\n",
        "\n",
        "**Group Number**: 7  \n",
        "\n",
        "---\n",
        "## Part 1: Data Augmentation on CSV Files"
      ],
      "metadata": {
        "id": "C5XUMV3kyA_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Load the dataset"
      ],
      "metadata": {
        "id": "_wR1O0-wyp0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "path = '/content/customer_transactions.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "DumscmEct8DA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Data Cleaning & Handling Missing Values"
      ],
      "metadata": {
        "id": "IUC3Tn2Uy-bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYrhNjvWvD6Y",
        "outputId": "053f349d-2e18-426b-91d9-c4955f7c2b16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_id_legacy     0\n",
            "transaction_id         0\n",
            "purchase_amount        0\n",
            "purchase_date          0\n",
            "product_category       0\n",
            "customer_rating       10\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing customer_rating values with median imputation:\n",
        "df['customer_rating'].fillna(df['customer_rating'].median(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuQfYw-vXF9",
        "outputId": "01d83d34-ad3d-48f9-9f9a-a4f0135b3ac3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7defe411dded>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['customer_rating'].fillna(df['customer_rating'].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values again\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVc9unV4vfqJ",
        "outputId": "428d1430-1985-44af-a156-a4c74c731446"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_id_legacy    0\n",
            "transaction_id        0\n",
            "purchase_amount       0\n",
            "purchase_date         0\n",
            "product_category      0\n",
            "customer_rating       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Data Augmentation Strategies"
      ],
      "metadata": {
        "id": "faaqsQhbzQLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Add random noise to purchase_amount\n",
        "noise = np.random.normal(0, 10, size=len(df))\n",
        "df['purchase_amount'] = df['purchase_amount'] + noise"
      ],
      "metadata": {
        "id": "jzDqa3PPv3Pt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Apply log transformation to purchase_amount\n",
        "df['log_purchase_amount'] = np.log1p(df['purchase_amount'])"
      ],
      "metadata": {
        "id": "8r7flxWcKnOa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a binary target column (e.g., high vs. low purchase amount)\n",
        "df['target'] = (df['purchase_amount'] > df['purchase_amount'].median()).astype(int)\n",
        "\n",
        "# Check the distribution of the target variable\n",
        "print(df['target'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMjkj5MzwczL",
        "outputId": "c62d83f0-2e49-4cc3-d0e9-824783d801f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "1    75\n",
            "0    75\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Synthetic Data Generation"
      ],
      "metadata": {
        "id": "ZNHwaUMD_OQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Synthetic Data Generation\n",
        "def generate_synthetic_data(df, num_samples=100):\n",
        "    synthetic_data = df.sample(n=num_samples, replace=True)\n",
        "    # Add variations (adjust as needed)\n",
        "    synthetic_data['purchase_amount'] *= np.random.uniform(0.9, 1.1, size=num_samples)\n",
        "    synthetic_data['product_category'] = np.random.choice(df['product_category'].unique(), size=num_samples)\n",
        "    # Ensure 'purchase_date' is datetime before adding timedelta\n",
        "    synthetic_data['purchase_date'] = pd.to_datetime(synthetic_data['purchase_date'], errors='coerce')\n",
        "    synthetic_data['purchase_date'] = synthetic_data['purchase_date'] + pd.to_timedelta(np.random.randint(-3, 3, size=num_samples), unit='days')\n",
        "    synthetic_data['customer_rating'] += np.random.uniform(-0.2, 0.2, size=num_samples)\n",
        "\n",
        "    # Clip customer_rating to be within the original range\n",
        "    synthetic_data['customer_rating'] = synthetic_data['customer_rating'].clip(lower=df['customer_rating'].min(), upper=df['customer_rating'].max())\n",
        "    return synthetic_data\n",
        "\n",
        "synthetic_data = generate_synthetic_data(df)\n",
        "df_augmented = pd.concat([df, synthetic_data], ignore_index=True)"
      ],
      "metadata": {
        "id": "xroYt-Iu3eC9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "NLohQTwz_gjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Extract purchase_month\n",
        "df_augmented['purchase_month'] = pd.to_datetime(df_augmented['purchase_date']).dt.month\n",
        "\n",
        "# 2. Calculate avg_purchase_amount per customer\n",
        "avg_purchase = df_augmented.groupby('customer_id_legacy')['purchase_amount'].mean().reset_index()\n",
        "avg_purchase.columns = ['customer_id_legacy', 'avg_purchase_amount']\n",
        "df_augmented = pd.merge(df_augmented, avg_purchase, on='customer_id_legacy', how='left')"
      ],
      "metadata": {
        "id": "dkI3n6KL3ofc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Calculate days_since_last_purchase\n",
        "df_augmented.sort_values(by=['customer_id_legacy', 'purchase_date'], inplace=True)\n",
        "df_augmented['purchase_date'] = pd.to_datetime(df_augmented['purchase_date'], errors='coerce')\n",
        "df_augmented.dropna(subset=['purchase_date'], inplace=True)\n",
        "df_augmented['days_since_last_purchase'] = df_augmented.groupby('customer_id_legacy')['purchase_date'].diff().dt.days\n",
        "df_augmented['days_since_last_purchase'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eu6TrSnGVly",
        "outputId": "e37244d8-62b0-4df3-b236-dd0cb53747d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f5db9a43e470>:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_augmented['days_since_last_purchase'].fillna(0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export the Augmented Dataset"
      ],
      "metadata": {
        "id": "a7NhUQax_VNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the augmented dataset\n",
        "df_augmented.to_csv('customer_transactions_augmented.csv', index=False)"
      ],
      "metadata": {
        "id": "Wkbp2aaq3sdh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2 Merging Datasets with Transitive Properties"
      ],
      "metadata": {
        "id": "W9sSTbXrnZJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "transactions_df = pd.read_csv('customer_transactions_augmented.csv')\n",
        "profiles_df = pd.read_csv('customer_social_profiles.csv')\n",
        "mapping_df = pd.read_csv('id_mapping.csv')\n",
        "\n",
        "print(\"Transactions DataFrame:\")\n",
        "print(transactions_df.head())\n",
        "print(\"\\nProfiles DataFrame:\")\n",
        "print(profiles_df.head())\n",
        "print(\"\\nMapping DataFrame:\")\n",
        "print(mapping_df.head())"
      ],
      "metadata": {
        "id": "fAln7KgNoFg6",
        "outputId": "33439d0d-be9c-4ae9-f661-7266fb130cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transactions DataFrame:\n",
            "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
            "0                 100            1147       380.875809    2024-05-23   \n",
            "1                 100            1147       438.797227    2024-05-26   \n",
            "2                 100            1113       161.031026    2024-04-22   \n",
            "3                 100            1147       402.142240    2024-05-26   \n",
            "4                 101            1021       184.970380    2024-01-19   \n",
            "\n",
            "  product_category  customer_rating  log_purchase_amount  target  \\\n",
            "0         Clothing         4.428340             5.999289       1   \n",
            "1            Books         4.427431             5.999289       1   \n",
            "2         Clothing         4.000000             5.087788       0   \n",
            "3            Books         4.600000             5.999289       1   \n",
            "4      Electronics         3.480945             5.230147       0   \n",
            "\n",
            "   purchase_month  avg_purchase_amount  days_since_last_purchase  \n",
            "0               5           345.711576                       0.0  \n",
            "1               5           345.711576                       3.0  \n",
            "2               4           345.711576                     -34.0  \n",
            "3               5           345.711576                      34.0  \n",
            "4               1           218.663506                       0.0  \n",
            "\n",
            "Profiles DataFrame:\n",
            "  customer_id_new social_media_platform  engagement_score  \\\n",
            "0            A178              LinkedIn                74   \n",
            "1            A190               Twitter                82   \n",
            "2            A150              Facebook                96   \n",
            "3            A162               Twitter                89   \n",
            "4            A197               Twitter                92   \n",
            "\n",
            "   purchase_interest_score review_sentiment  \n",
            "0                      4.9         Positive  \n",
            "1                      4.8          Neutral  \n",
            "2                      1.6         Positive  \n",
            "3                      2.6         Positive  \n",
            "4                      2.3          Neutral  \n",
            "\n",
            "Mapping DataFrame:\n",
            "   customer_id_legacy customer_id_new\n",
            "0                 195            A105\n",
            "1                 161            A118\n",
            "2                 192            A156\n",
            "3                 157            A168\n",
            "4                 166            A102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Understand the ID Mapping\n"
      ],
      "metadata": {
        "id": "ISObTuP_oM1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMapping DataFrame Info:\")\n",
        "print(mapping_df.info())\n",
        "print(\"\\nUnique Legacy IDs in Mapping:\", mapping_df['customer_id_legacy'].nunique())\n",
        "print(\"Unique New IDs in Mapping:\", mapping_df['customer_id_new'].nunique())"
      ],
      "metadata": {
        "id": "Dm6WulCioOXy",
        "outputId": "31d82b04-5107-48d2-a512-5d146efffed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mapping DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 155 entries, 0 to 154\n",
            "Data columns (total 2 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   customer_id_legacy  155 non-null    int64 \n",
            " 1   customer_id_new     155 non-null    object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.6+ KB\n",
            "None\n",
            "\n",
            "Unique Legacy IDs in Mapping: 79\n",
            "Unique New IDs in Mapping: 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge transactions with mapping"
      ],
      "metadata": {
        "id": "yLno38JaoZLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_transactions_mapping = pd.merge(transactions_df, mapping_df, on='customer_id_legacy', how='left')\n",
        "print(\"\\nMerged Transactions and Mapping DataFrame:\")\n",
        "print(merged_transactions_mapping.head())"
      ],
      "metadata": {
        "id": "faxW0KZ4oeum",
        "outputId": "bf3f160c-538d-4965-e23f-188491bbadfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Merged Transactions and Mapping DataFrame:\n",
            "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
            "0                 100            1147       380.875809    2024-05-23   \n",
            "1                 100            1147       438.797227    2024-05-26   \n",
            "2                 100            1113       161.031026    2024-04-22   \n",
            "3                 100            1147       402.142240    2024-05-26   \n",
            "4                 101            1021       184.970380    2024-01-19   \n",
            "\n",
            "  product_category  customer_rating  log_purchase_amount  target  \\\n",
            "0         Clothing         4.428340             5.999289       1   \n",
            "1            Books         4.427431             5.999289       1   \n",
            "2         Clothing         4.000000             5.087788       0   \n",
            "3            Books         4.600000             5.999289       1   \n",
            "4      Electronics         3.480945             5.230147       0   \n",
            "\n",
            "   purchase_month  avg_purchase_amount  days_since_last_purchase  \\\n",
            "0               5           345.711576                       0.0   \n",
            "1               5           345.711576                       3.0   \n",
            "2               4           345.711576                     -34.0   \n",
            "3               5           345.711576                      34.0   \n",
            "4               1           218.663506                       0.0   \n",
            "\n",
            "  customer_id_new  \n",
            "0             NaN  \n",
            "1             NaN  \n",
            "2             NaN  \n",
            "3             NaN  \n",
            "4            A116  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge the result with profiles"
      ],
      "metadata": {
        "id": "d0rT0Rhxoj8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged_df = pd.merge(merged_transactions_mapping, profiles_df, on='customer_id_new', how='left')\n",
        "print(\"\\nFinal Merged DataFrame:\")\n",
        "print(final_merged_df.head())"
      ],
      "metadata": {
        "id": "M0uvfIQbolaf",
        "outputId": "8670f4dc-47b4-49ba-dca5-bac60beab34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Merged DataFrame:\n",
            "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
            "0                 100            1147       380.875809    2024-05-23   \n",
            "1                 100            1147       438.797227    2024-05-26   \n",
            "2                 100            1113       161.031026    2024-04-22   \n",
            "3                 100            1147       402.142240    2024-05-26   \n",
            "4                 101            1021       184.970380    2024-01-19   \n",
            "\n",
            "  product_category  customer_rating  log_purchase_amount  target  \\\n",
            "0         Clothing         4.428340             5.999289       1   \n",
            "1            Books         4.427431             5.999289       1   \n",
            "2         Clothing         4.000000             5.087788       0   \n",
            "3            Books         4.600000             5.999289       1   \n",
            "4      Electronics         3.480945             5.230147       0   \n",
            "\n",
            "   purchase_month  avg_purchase_amount  days_since_last_purchase  \\\n",
            "0               5           345.711576                       0.0   \n",
            "1               5           345.711576                       3.0   \n",
            "2               4           345.711576                     -34.0   \n",
            "3               5           345.711576                      34.0   \n",
            "4               1           218.663506                       0.0   \n",
            "\n",
            "  customer_id_new social_media_platform  engagement_score  \\\n",
            "0             NaN                   NaN               NaN   \n",
            "1             NaN                   NaN               NaN   \n",
            "2             NaN                   NaN               NaN   \n",
            "3             NaN                   NaN               NaN   \n",
            "4            A116               Twitter              78.0   \n",
            "\n",
            "   purchase_interest_score review_sentiment  \n",
            "0                      NaN              NaN  \n",
            "1                      NaN              NaN  \n",
            "2                      NaN              NaN  \n",
            "3                      NaN              NaN  \n",
            "4                      1.1         Negative  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Conflicts"
      ],
      "metadata": {
        "id": "46MFn5Waot1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is to check if any other issues caused duplicates.\n",
        "if 'transaction_id' in final_merged_df.columns:\n",
        "    final_duplicates = final_merged_df[final_merged_df.duplicated(subset=['transaction_id'], keep=False)]\n",
        "    if not final_duplicates.empty:\n",
        "        print(\"\\nPotential duplicates in final_merged_df based on transaction_id (after handling mapping):\")\n",
        "        print(final_duplicates.head())\n",
        "        print(f\"Total potential duplicates: {len(final_duplicates)}\")\n",
        "    else:\n",
        "        print(\"\\nNo duplicates found in final_merged_df based on transaction_id after handling mapping conflicts.\")\n",
        "else:\n",
        "    print(\"\\nWarning: 'transaction_id' column not found, cannot check for duplicates based on it.\")"
      ],
      "metadata": {
        "id": "xmwubGXkovSg",
        "outputId": "1d6677d0-862e-4cca-8a8a-28f10f68fee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Potential duplicates in final_merged_df based on transaction_id (after handling mapping):\n",
            "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
            "0                 100            1147       380.875809    2024-05-23   \n",
            "1                 100            1147       438.797227    2024-05-26   \n",
            "3                 100            1147       402.142240    2024-05-26   \n",
            "4                 101            1021       184.970380    2024-01-19   \n",
            "5                 101            1021       184.970380    2024-01-19   \n",
            "\n",
            "  product_category  customer_rating  log_purchase_amount  target  \\\n",
            "0         Clothing         4.428340             5.999289       1   \n",
            "1            Books         4.427431             5.999289       1   \n",
            "3            Books         4.600000             5.999289       1   \n",
            "4      Electronics         3.480945             5.230147       0   \n",
            "5      Electronics         3.480945             5.230147       0   \n",
            "\n",
            "   purchase_month  avg_purchase_amount  days_since_last_purchase  \\\n",
            "0               5           345.711576                       0.0   \n",
            "1               5           345.711576                       3.0   \n",
            "3               5           345.711576                      34.0   \n",
            "4               1           218.663506                       0.0   \n",
            "5               1           218.663506                       0.0   \n",
            "\n",
            "  customer_id_new social_media_platform  engagement_score  \\\n",
            "0             NaN                   NaN               NaN   \n",
            "1             NaN                   NaN               NaN   \n",
            "3             NaN                   NaN               NaN   \n",
            "4            A116               Twitter              78.0   \n",
            "5            A116              LinkedIn              89.0   \n",
            "\n",
            "   purchase_interest_score review_sentiment  \n",
            "0                      NaN              NaN  \n",
            "1                      NaN              NaN  \n",
            "3                      NaN              NaN  \n",
            "4                      1.1         Negative  \n",
            "5                      2.4          Neutral  \n",
            "Total potential duplicates: 615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Engagement Score"
      ],
      "metadata": {
        "id": "V7y6EzwAo-I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDataFrame after potential Engagement Score creation:\")\n",
        "print(final_merged_df.head())"
      ],
      "metadata": {
        "id": "AX-xsnHlo_YT",
        "outputId": "afcce33d-2956-4d81-918a-83fe908e8173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after potential Engagement Score creation:\n",
            "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
            "0                 100            1147       380.875809    2024-05-23   \n",
            "1                 100            1147       438.797227    2024-05-26   \n",
            "2                 100            1113       161.031026    2024-04-22   \n",
            "3                 100            1147       402.142240    2024-05-26   \n",
            "4                 101            1021       184.970380    2024-01-19   \n",
            "\n",
            "  product_category  customer_rating  log_purchase_amount  target  \\\n",
            "0         Clothing         4.428340             5.999289       1   \n",
            "1            Books         4.427431             5.999289       1   \n",
            "2         Clothing         4.000000             5.087788       0   \n",
            "3            Books         4.600000             5.999289       1   \n",
            "4      Electronics         3.480945             5.230147       0   \n",
            "\n",
            "   purchase_month  avg_purchase_amount  days_since_last_purchase  \\\n",
            "0               5           345.711576                       0.0   \n",
            "1               5           345.711576                       3.0   \n",
            "2               4           345.711576                     -34.0   \n",
            "3               5           345.711576                      34.0   \n",
            "4               1           218.663506                       0.0   \n",
            "\n",
            "  customer_id_new social_media_platform  engagement_score  \\\n",
            "0             NaN                   NaN               NaN   \n",
            "1             NaN                   NaN               NaN   \n",
            "2             NaN                   NaN               NaN   \n",
            "3             NaN                   NaN               NaN   \n",
            "4            A116               Twitter              78.0   \n",
            "\n",
            "   purchase_interest_score review_sentiment  \n",
            "0                      NaN              NaN  \n",
            "1                      NaN              NaN  \n",
            "2                      NaN              NaN  \n",
            "3                      NaN              NaN  \n",
            "4                      1.1         Negative  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineer predictive behavioral features"
      ],
      "metadata": {
        "id": "Ft1boMC4pKmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving Averages of Transactions (Adapted)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "if 'purchase_date' in transactions_df.columns and 'purchase_amount' in transactions_df.columns:\n",
        "    # Convert purchase_date to datetime\n",
        "    transactions_df['purchase_date'] = pd.to_datetime(transactions_df['purchase_date'])\n",
        "\n",
        "    # Sort transactions by customer and date\n",
        "    transactions_df = transactions_df.sort_values(by=['customer_id_legacy', 'purchase_date'])\n",
        "\n",
        "    # Set 'purchase_date' as the index for the rolling calculation\n",
        "    transactions_df = transactions_df.set_index('purchase_date')\n",
        "\n",
        "    # Define time windows for moving averages (e.g., 7 days, 30 days).\n",
        "    time_windows = ['7D', '30D']\n",
        "\n",
        "    for window in time_windows:\n",
        "        # Calculate rolling mean of purchase amount\n",
        "        transactions_df[f'purchase_amount_rolling_{window}'] = transactions_df.groupby('customer_id_legacy')['purchase_amount'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "    # Reset the index if you need 'purchase_date' as a column later\n",
        "    transactions_df = transactions_df.reset_index()\n",
        "\n",
        "    print(\"\\nTransactions DataFrame with Moving Averages:\")\n",
        "    print(transactions_df.head())\n",
        "else:\n",
        "    print(\"Warning: 'purchase_date' or 'purchase_amount' column not found in transactions_df. Skipping Moving Averages.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3WSRZmvWpNgp",
        "outputId": "e39ea1d2-bee3-46e4-d60d-4c93c6ef2a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transactions DataFrame with Moving Averages:\n",
            "  purchase_date  customer_id_legacy  transaction_id  purchase_amount  \\\n",
            "0    2024-04-22                 100            1113       161.031026   \n",
            "1    2024-05-23                 100            1147       380.875809   \n",
            "2    2024-05-26                 100            1147       438.797227   \n",
            "3    2024-05-26                 100            1147       402.142240   \n",
            "4    2024-01-17                 101            1017       271.942110   \n",
            "\n",
            "  product_category  customer_rating  log_purchase_amount  target  \\\n",
            "0         Clothing         4.000000             5.087788       0   \n",
            "1         Clothing         4.428340             5.999289       1   \n",
            "2            Books         4.427431             5.999289       1   \n",
            "3            Books         4.600000             5.999289       1   \n",
            "4            Books         2.100000             5.609260       0   \n",
            "\n",
            "   purchase_month  avg_purchase_amount  days_since_last_purchase  \\\n",
            "0               4           345.711576                     -34.0   \n",
            "1               5           345.711576                       0.0   \n",
            "2               5           345.711576                       3.0   \n",
            "3               5           345.711576                      34.0   \n",
            "4               1           218.663506                     -55.0   \n",
            "\n",
            "   purchase_amount_rolling_7D  purchase_amount_rolling_30D  \n",
            "0                  161.031026                   161.031026  \n",
            "1                  380.875809                   380.875809  \n",
            "2                  409.836518                   409.836518  \n",
            "3                  407.271759                   407.271759  \n",
            "4                  271.942110                   271.942110  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Time-based Aggregation of Purchases (Adapted)\n",
        "if 'purchase_date' in transactions_df.columns and 'purchase_amount' in transactions_df.columns:\n",
        "    # Convert purchase_date to datetime (if not already done)\n",
        "    transactions_df['purchase_date'] = pd.to_datetime(transactions_df['purchase_date'])\n",
        "\n",
        "    # Define a reference date (e.g., the latest purchase date in the dataset)\n",
        "    reference_date = transactions_df['purchase_date'].max()\n",
        "\n",
        "    # Calculate time differences\n",
        "    transactions_df['days_since_purchase'] = (reference_date - transactions_df['purchase_date']).dt.days\n",
        "\n",
        "    # Aggregate features per customer\n",
        "    aggregated_purchases = transactions_df.groupby('customer_id_legacy').agg(\n",
        "        total_purchase_amount=('purchase_amount', 'sum'),\n",
        "        number_of_transactions=('transaction_id', 'nunique'),\n",
        "        average_purchase_value=('purchase_amount', 'mean'),\n",
        "        last_purchase_days=('days_since_purchase', 'min')\n",
        "    ).reset_index()\n",
        "\n",
        "    print(\"\\nAggregated Purchase Features per Customer:\")\n",
        "    print(aggregated_purchases.head())\n",
        "\n",
        "    # Merge aggregated features into final_merged_df\n",
        "    final_merged_df = pd.merge(final_merged_df, aggregated_purchases, on='customer_id_legacy', how='left')\n",
        "else:\n",
        "    print(\"Warning: 'purchase_date' or 'purchase_amount' column not found in transactions_df. Skipping Time-based Aggregation.\")"
      ],
      "metadata": {
        "id": "WJUln_tFphUn",
        "outputId": "c4995822-2f51-4d7f-c264-20d522b08833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Aggregated Purchase Features per Customer:\n",
            "   customer_id_legacy  total_purchase_amount  number_of_transactions  \\\n",
            "0                 100            1382.846303                       2   \n",
            "1                 101            1530.644541                       4   \n",
            "2                 102            1189.774113                       3   \n",
            "3                 103            1237.305302                       3   \n",
            "4                 104             711.435280                       2   \n",
            "\n",
            "   average_purchase_value  last_purchase_days  \n",
            "0              345.711576                   3  \n",
            "1              218.663506                  77  \n",
            "2              198.295686                   4  \n",
            "3              309.326325                  74  \n",
            "4              355.717640                   2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF on Customer Reviews or Social Media Comments\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "if 'social_media_text' in profiles_df.columns:\n",
        "    text_column = 'social_media_text'\n",
        "    text_data = profiles_df[['customer_id_new', text_column]].dropna()\n",
        "\n",
        "    if not text_data.empty:\n",
        "        # Initialize TF-IDF Vectorizer\n",
        "        tfidf_vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "\n",
        "        # Fit and transform the text data\n",
        "        tfidf_matrix = tfidf_vectorizer.fit_transform(text_data[text_column])\n",
        "\n",
        "        # Get feature names (words)\n",
        "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "        # Create a DataFrame of TF-IDF features\n",
        "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{word}' for word in feature_names])\n",
        "\n",
        "        # Concatenate with customer IDs (customer_id_new in this case)\n",
        "        tfidf_df = pd.concat([text_data['customer_id_new'].reset_index(drop=True), tfidf_df], axis=1)\n",
        "\n",
        "        # Aggregate TF-IDF features by customer (e.g., taking the mean)\n",
        "        tfidf_aggregated = tfidf_df.groupby('customer_id_new').mean().reset_index()\n",
        "\n",
        "        print(\"\\nAggregated TF-IDF Features from Social Media Text:\")\n",
        "        print(tfidf_aggregated.head())\n",
        "\n",
        "        # Merge TF-IDF features into final_merged_df using customer_id_new\n",
        "        final_merged_df = pd.merge(final_merged_df, tfidf_aggregated, on='customer_id_new', how='left')\n",
        "    else:\n",
        "        print(f\"No non-missing values found in the '{text_column}' column of profiles_df.\")\n",
        "\n",
        "else:\n",
        "    print(\"Warning: 'social_media_text' column not found in profiles_df. Skipping TF-IDF.\")"
      ],
      "metadata": {
        "id": "GG0_aQMJqlPO",
        "outputId": "7f277475-8ba6-46c5-a452-8a55e42695c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'social_media_text' column not found in profiles_df. Skipping TF-IDF.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export the Final Preprocessed Data"
      ],
      "metadata": {
        "id": "GHjlbOGIq5ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_number = \"7\"\n",
        "output_filename = f'final_customer_data_{7}.csv'\n",
        "final_merged_df.to_csv(output_filename, index=False)\n",
        "print(f\"\\nFinal preprocessed data saved to: {output_filename}\")"
      ],
      "metadata": {
        "id": "v0flKMhBq7Cw",
        "outputId": "84b95440-f003-437c-ee81-fcd2cdcae7db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final preprocessed data saved to: final_customer_data_7.csv\n"
          ]
        }
      ]
    }
  ]
}