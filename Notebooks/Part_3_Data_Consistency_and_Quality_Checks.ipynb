{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRx7TSqGaNpQw39W2ztLGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joh-Ishimwe/Data-Preprocessing/blob/master/Part_3_Data_Consistency_and_Quality_Checks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Integrity Checks"
      ],
      "metadata": {
        "id": "HvDbpY3E7-De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzMXvqs47rU4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the merged dataset from Part 2\n",
        "df_final = pd.read_csv('final_customer_data_7.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check for duplicate entries\n",
        "duplicates = df_final.duplicated().sum()\n",
        "print(f\"Number of duplicate entries: {duplicates}\")\n",
        "if duplicates > 0:\n",
        "    df_final = df_final.drop_duplicates()\n",
        "    print(\"Duplicates removed.\")\n",
        "\n",
        "# 2. Ensure categorical values are correctly mapped\n",
        "categorical_columns = ['product_category', 'social_media_platform', 'review_sentiment']\n",
        "for col in categorical_columns:\n",
        "    unique_values = df_final[col].unique()\n",
        "    print(f\"Unique values in {col}: {unique_values}\")\n",
        "\n",
        "# 3. Validate customer transactions match a valid social profile\n",
        "# Check if customer_id_new has corresponding social_media_platform when not NaN\n",
        "mismatched = df_final[(df_final['customer_id_new'].notna()) & (df_final['social_media_platform'].isna())]\n",
        "print(f\"Transactions with customer_id_new but no social_media_platform: {len(mismatched)}\")\n",
        "if len(mismatched) > 0:\n",
        "    print(\"Sample mismatched rows:\")\n",
        "    print(mismatched[['customer_id_legacy', 'customer_id_new', 'social_media_platform']].head())"
      ],
      "metadata": {
        "id": "VKH2HU_C8DZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Statistical Summarization"
      ],
      "metadata": {
        "id": "0LeTmlS18NiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate describe() reports for numerical columns\n",
        "numerical_columns = df_final.select_dtypes(include=[np.number]).columns\n",
        "print(\"\\nStatistical Summary of Numerical Columns:\")\n",
        "print(df_final[numerical_columns].describe())\n",
        "\n",
        "# Visualize distribution of transaction amounts before and after augmentation\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df_final['purchase_amount'], bins=30, kde=True)\n",
        "plt.title('Distribution of Original Purchase Amount')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df_final['purchase_amount_noisy'], bins=30, kde=True)\n",
        "plt.title('Distribution of Noisy Purchase Amount')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8aZJxMeV8ICE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature Selection for Machine Learning"
      ],
      "metadata": {
        "id": "yM0z0rrF8Vza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = df_final[numerical_columns].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()\n",
        "\n",
        "# Prepare features and target (predicting 'target' since it's present)\n",
        "features_to_drop = ['target', 'purchase_date', 'customer_id_legacy', 'customer_id_new',\n",
        "                    'transaction_id'] + categorical_columns\n",
        "features_to_drop = [col for col in features_to_drop if col in df_final.columns]\n",
        "features = df_final.drop(columns=features_to_drop)\n",
        "X = features.fillna(0)  # Fill NaN for feature selection\n",
        "y = df_final['target'].fillna(df_final['target'].mean())\n",
        "\n",
        "# Select top 10 features\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "selector.fit(X, y)\n",
        "selected_features = X.columns[selector.get_support()].tolist()\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "for i, (feature, score) in enumerate(zip(selected_features, selector.scores_[selector.get_support()]), 1):\n",
        "    print(f\"{i}. {feature}: {score:.2f}\")"
      ],
      "metadata": {
        "id": "MlAzfvVM8XmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Final Data Export\n",
        "final_columns = (['customer_id_legacy', 'customer_id_new', 'transaction_id', 'purchase_date'] +\n",
        "                 categorical_columns + selected_features + ['target'])\n",
        "final_columns = [col for col in final_columns if col in df_final.columns]\n",
        "final_dataset = df_final[final_columns]\n",
        "\n",
        "# Save the final dataset\n",
        "final_dataset.to_csv('final_dataset_ready_7.csv', index=False)\n",
        "print(\"\\nFinal dataset saved as 'final_dataset_ready_7.csv'\")"
      ],
      "metadata": {
        "id": "HibWviZW8g92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}